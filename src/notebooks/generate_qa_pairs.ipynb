{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from queue import Queue\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "\n",
    "from gemini_api import GeminiAPIHandler\n",
    "\n",
    "api_requests_file = \"api_requests/api_requests_hiba.json\"\n",
    "output_dir = Path(\"api_results\") / \"hiba\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "log_filename = os.path.join(output_dir, f\"api_resultscont.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \n",
    "    filename=log_filename\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "model_name = \"gemini-2.0-flash-exp\"\n",
    "#model_name = \"gemini-2.0-flash-thinking-exp\"\n",
    "\n",
    "api_handler = GeminiAPIHandler(api_key=api_key, model_name=model_name)\n",
    "\n",
    "with open(api_requests_file, \"r\") as file:\n",
    "    api_requests = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini_api(request: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Call the Gemini API for a given request and dataset image path.\n",
    "    \"\"\"\n",
    "    image_id = request.get(\"image_id\")\n",
    "    image_path = request.get(\"image_path\")\n",
    "            \n",
    "    # Get 2 prompts\n",
    "    q1_general = request.get(\"q1_general\")['prompt']\n",
    "    q2_dataset_specific = request.get(\"q2_dataset_specific\")['prompt']\n",
    "    \n",
    "    # Load the image\n",
    "    with Image.open(image_path) as pil_image:\n",
    "        # Generate response for general prompt\n",
    "        q1_general_response = api_handler.generate_from_pil_image(pil_image, q1_general)\n",
    "        # Generate response for dataset-specific prompt\n",
    "        q2_dataset_response = api_handler.generate_from_pil_image(pil_image, q2_dataset_specific)\n",
    "        \n",
    "    # Save the responses\n",
    "    result = {\n",
    "        \"image_id\": image_id,\n",
    "        \"image_path\": image_path,\n",
    "        \n",
    "        # Save the responses\n",
    "        \"q1_general_response\": q1_general_response,\n",
    "        \"q2_dataset_response\": q2_dataset_response,\n",
    "        \n",
    "        # Save the questions\n",
    "        \"q1_general_question\": request.get(\"q1_general\")['question'],\n",
    "        \"q2_dataset_question\": request.get(\"q2_dataset_specific\")['question'],\n",
    "        \n",
    "        # Save the prompts\n",
    "        \"q1_general_prompt\": q1_general,\n",
    "        \"q2_dataset_prompt\": q2_dataset_specific\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_queue = Queue()\n",
    "for req in api_requests:\n",
    "    requests_queue.put(req)\n",
    "\n",
    "results = []\n",
    "\n",
    "while not requests_queue.empty():\n",
    "    request = requests_queue.get()\n",
    "    task_exists = False\n",
    "    try:\n",
    "        image_id = request.get(\"image_id\")\n",
    "        generated_response_file = output_dir / f\"{image_id}_response.json\"\n",
    "        \n",
    "        if os.path.exists(generated_response_file):\n",
    "            logger.info(f\"Skipping image_id {image_id} as response already exists.\")\n",
    "            task_exists = True\n",
    "\n",
    "        else:\n",
    "            result = call_gemini_api(request)\n",
    "            results.append(result)\n",
    "            with open(generated_response_file, \"w\") as out_file:\n",
    "                json.dump(result, out_file, indent=4)\n",
    "            logger.info(f\"Successfully processed image_id {image_id}, saved to {generated_response_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error processing image_id {image_id}: {e}\")\n",
    "        \n",
    "        # Requeue the request\n",
    "        requests_queue.put(request)\n",
    "\n",
    "    finally:\n",
    "        requests_queue.task_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
